all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
axis(1, at = matrix_data$Time, labels = format(matrix_data$Time, "%b"))
?matplot
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature" , xaxt = "n")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
month_start <- format(matrix_data$Time, "%d") == "01"
axis(1, at = matrix_data$Time[month_start], labels = format(matrix_data$Time[month_start], "%b"))
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature" , xaxt = "n")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
rownames(matplot_matrix)
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(format(as.Date(rownames(matplot_matrix)), "%b %d"), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
format(as.Date(rownames(matplot_matrix)), "%b %d")
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
# It was found via trial and error, that the first table contained the information we wanted
cities = as.data.frame(html_table(tabs[1]))
# Get the top 5 cities
top_cities = cities[order(cities$population, decreasing= TRUE),][1:5,]
# Get all the website URLS that we need
website_url = paste0("https://archive-api.open-meteo.com/v1/archive?latitude=",top_cities$lat,"&longitude=",top_cities$lng,"&start_date=2022-01-01&end_date=2022-12-31&daily=temperature_2m_max&timezone=Pacific%2FAuckland")
# Store the dataframes all into one
all_data = lapply(website_url, function(x)
{data = fromJSON(url(x))
return(data.frame(as.Date(data$daily$time), data$daily$temperature_2m_max))
})
# For each dataframe, we want to create a column that contains the city associated with the data
for (i in 1:5) {
all_data[[i]]$city = top_cities$city[i]
}
# Put it all into one dataframe
matrix_data = do.call(rbind, all_data)
colnames(matrix_data) = c("Time", "Temperature", "City")
# Then we can use xtabs to get our dataset into matrix form
matplot_matrix <- xtabs(Temperature ~ Time + City, matrix_data)
# Then we can plot our plot using matplot
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
legend("bottomleft", legend = colnames(matplot_matrix), col = 1:5, lty = 1, cex = 0.6)
?plot
matplot_matrix
range(rownames(matplot_matrix))
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
range(rownames(matplot_matrix))
dim(matplot_matrix)
range(as.Date(rownames(matplot_matrix)))
sessionInfo()
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
axis.Date(1, as.Date(rownames(matplot_matrix)))
str(axis.Date(1, as.Date(rownames(matplot_matrix))))
axis.Date
saveRDS(matplot_matrix, file="/tmp/x.rds")
str(axis.Date(1, as.Date(rownames(matplot_matrix))))
unclass(axis.Date(1, as.Date(rownames(matplot_matrix))))
attributes(axis.Date(1, as.Date(rownames(matplot_matrix))))
axis.Date
a=axis.Date(1, as.Date(rownames(matplot_matrix)))
axis.Date(1, as.Date(rownames(matplot_matrix)), a)
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature")
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature", axis=F)
matplot(as.Date(rownames(matplot_matrix)), matplot_matrix, type = "l", lty= 1, xlab = "Day", ylab = "max. temperature", axes=F)
axis.Date(1, as.Date(rownames(matplot_matrix)), a)
a=axis.Date(1, as.Date(rownames(matplot_matrix)))
stops = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stops.txt", header = TRUE, sep = ",", quote = "")
stop_times = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stop_times.txt", header = TRUE, sep = ",", quote = "")
trips = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/trips.txt", header = TRUE, sep = ",", quote = "", fill = TRUE)
routes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/routes.txt", header = TRUE, sep = ",", quote = "")
shapes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/shapes.txt", header = TRUE, sep = ",", quote = "")
stop_times = stop_times %>% mutate(stop_code = substring(stop_id, 1, regexpr("-", stop_id)[1] - 1))
library(tidyverse)
library(leaflet)
library(jsonlite)
library(httr)
stops = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stops.txt", header = TRUE, sep = ",", quote = "")
stop_times = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stop_times.txt", header = TRUE, sep = ",", quote = "")
trips = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/trips.txt", header = TRUE, sep = ",", quote = "", fill = TRUE)
routes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/routes.txt", header = TRUE, sep = ",", quote = "")
shapes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/shapes.txt", header = TRUE, sep = ",", quote = "")
stop_times = stop_times %>% mutate(stop_code = substring(stop_id, 1, regexpr("-", stop_id)[1] - 1))
stops
stop_times
trips
routes
shapes
stop_times
colnames(stops)
colnames(stop_times)
trips
routes
shapes
stop_times
library(tidyverse)
library(leaflet)
library(jsonlite)
library(httr)
key = "567bb1fb7ab64582905c7812648075e1"
#Reading in static files
stops = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stops.txt", header = TRUE, sep = ",", quote = "")
stop_times = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stop_times.txt", header = TRUE, sep = ",", quote = "")
trips = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/trips.txt", header = TRUE, sep = ",", quote = "", fill = TRUE)
routes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/routes.txt", header = TRUE, sep = ",", quote = "")
shapes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/shapes.txt", header = TRUE, sep = ",", quote = "")
stop_times = stop_times %>% mutate(stop_code = substring(stop_id, 1, regexpr("-", stop_id)[1] - 1))
#colnames(stop_times)
#stop_times %>% filter(trip_id == "1184-07209-37680-2-75bd3e26")
#Stop_times column stop_code connects to stops$id
t = shapes %>% filter(shape_id == "957-12603-1bf4bceb")
t
leaflet(t) %>% addTiles() %>% addPolylines(data = t,  lat = t$shape_pt_lat, lng = t$shape_pt_lon)
#Combining stop times with
#Read in data
#Json File
gtfs_trips<-tryCatch(
GET('https://api.at.govt.nz/realtime/legacy/tripupdates',
accept_json(),
add_headers('Ocp-Apim-Subscription-Key' = key)),
error=function(e) NULL)
trip_content = content(gtfs_trips)[[2]][[2]]
#head(str(trip_content), level = 3)
head(trip_content)
#Helper Functions
n = function(x) if(is.null(x)) NA else x
trip_data = as.data.frame(do.call(rbind, lapply(trip_content,
function(x) c(n(x$trip_update$trip$trip_id),
n(x$trip_update$trip$direction_id),
n(x$trip_update$trip$route_id),
n(x$trip_update$stop_time_update$stop_id),
n(x$trip_update$trip$schedule_relationship),
n(x$trip_update$delay),
n(x$trip_update$stop_time_update$stop_sequence),
n(x$trip_update$stop_time_update$arrival$time),
n(x$trip_update$stop_time_update$arrival$delay),
n(x$trip_update$stop_time_update$departure$time),
n(x$trip_update$stop_time_update$departure$delay)
))))
colnames(trip_data) = c("trip_id",
"direction_id",
"route_id",
"stop_id",
"schedule_relationship",
"delay",
"stop_sequence",
"act_arrival_time",
"arrival_delay",
"act_departure_time",
"act_departure_delay")
#Converting our types to be able to join
trip_data$stop_sequence = as.integer(trip_data$stop_sequence)
trip_data = trip_data %>% mutate(stop_code = as.integer(substring(stop_id, 1, regexpr("-", stop_id)[1] - 1)))
#Cancelled buses
alerts <- tryCatch(
GET('https://api.at.govt.nz/realtime/legacy/servicealerts',
accept_json(),
add_headers('Ocp-Apim-Subscription-Key' = key)),
error=function(e) NULL)
#Now alerts are different
alert_contents = content(alerts)
alert_data = as.data.frame(do.call(rbind, lapply(alert_contents[[2]][[2]], function(x) c(x$id, x$alert$effect, x$alert$header_text$translation[[1]]$text, x$alert$informed_entity[[1]]$trip$trip_id))))
colnames(alert_data) = c("id", "effect", "text", "trip_id")
alert_temp1 = alert_data
alert_temp1$trip_id = ifelse(alert_temp1$trip_id == alert_temp1$id, NA, alert_temp1$trip_id)
cancelled_buses = alert_temp1 %>% filter(is.na(trip_id) == FALSE) %>% select(trip_id) %>% mutate(cancelled = TRUE)
#Getting our full dataset by joining
df = trip_data %>%
left_join(stop_times %>% select("trip_id", "stop_sequence", "arrival_time", "departure_time"),
by = c("trip_id" = "trip_id", "stop_sequence" = "stop_sequence")) %>%
left_join(stops %>% select("stop_id", "stop_lat", "stop_lon"),
by = c("stop_id" = "stop_id")) %>%
left_join(routes %>% select("route_id", "route_short_name"),
by = c("route_id" = "route_id")) %>%
left_join(cancelled_buses,
by = c("trip_id" = "trip_id"))
df = df[order(df$trip_id, df$direction_id, df$stop_sequence, df$arrival_time),]
df
library(tidyverse)
library(leaflet)
library(jsonlite)
library(httr)
key = "567bb1fb7ab64582905c7812648075e1"
#Reading in static files
stops = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stops.txt", header = TRUE, sep = ",", quote = "")
stop_times = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/stop_times.txt", header = TRUE, sep = ",", quote = "")
trips = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/trips.txt", header = TRUE, sep = ",", quote = "", fill = TRUE)
routes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/routes.txt", header = TRUE, sep = ",", quote = "")
shapes = read.table("~/Desktop/2023/Thesis Project/Code for Project/gtfs/shapes.txt", header = TRUE, sep = ",", quote = "")
stop_times = stop_times %>% mutate(stop_code = substring(stop_id, 1, regexpr("-", stop_id)[1] - 1))
#colnames(stop_times)
#stop_times %>% filter(trip_id == "1184-07209-37680-2-75bd3e26")
#Stop_times column stop_code connects to stops$id
t = shapes %>% filter(shape_id == "957-12603-1bf4bceb")
t
leaflet(t) %>% addTiles() %>% addPolylines(data = t,  lat = t$shape_pt_lat, lng = t$shape_pt_lon)
#Combining stop times with
#Read in data
#Json File
gtfs_trips<-tryCatch(
GET('https://api.at.govt.nz/realtime/legacy/tripupdates',
accept_json(),
add_headers('Ocp-Apim-Subscription-Key' = key)),
error=function(e) NULL)
trip_content = content(gtfs_trips)[[2]][[2]]
#head(str(trip_content), level = 3)
head(trip_content)
#Helper Functions
n = function(x) if(is.null(x)) NA else x
trip_data = as.data.frame(do.call(rbind, lapply(trip_content,
function(x) c(n(x$trip_update$trip$trip_id),
n(x$trip_update$trip$direction_id),
n(x$trip_update$trip$route_id),
n(x$trip_update$stop_time_update$stop_id),
n(x$trip_update$trip$schedule_relationship),
n(x$trip_update$delay),
n(x$trip_update$stop_time_update$stop_sequence),
n(x$trip_update$stop_time_update$arrival$time),
n(x$trip_update$stop_time_update$arrival$delay),
n(x$trip_update$stop_time_update$departure$time),
n(x$trip_update$stop_time_update$departure$delay)
))))
colnames(trip_data) = c("trip_id",
"direction_id",
"route_id",
"stop_id",
"schedule_relationship",
"delay",
"stop_sequence",
"act_arrival_time",
"arrival_delay",
"act_departure_time",
"act_departure_delay")
#Converting our types to be able to join
trip_data$stop_sequence = as.integer(trip_data$stop_sequence)
trip_data = trip_data %>% mutate(stop_code = as.integer(substring(stop_id, 1, regexpr("-", stop_id)[1] - 1)))
#Cancelled buses
alerts <- tryCatch(
GET('https://api.at.govt.nz/realtime/legacy/servicealerts',
accept_json(),
add_headers('Ocp-Apim-Subscription-Key' = key)),
error=function(e) NULL)
#Now alerts are different
alert_contents = content(alerts)
alert_data = as.data.frame(do.call(rbind, lapply(alert_contents[[2]][[2]], function(x) c(x$id, x$alert$effect, x$alert$header_text$translation[[1]]$text, x$alert$informed_entity[[1]]$trip$trip_id))))
colnames(alert_data) = c("id", "effect", "text", "trip_id")
alert_temp1 = alert_data
alert_temp1$trip_id = ifelse(alert_temp1$trip_id == alert_temp1$id, NA, alert_temp1$trip_id)
cancelled_buses = alert_temp1 %>% filter(is.na(trip_id) == FALSE) %>% select(trip_id) %>% mutate(cancelled = TRUE)
#Getting our full dataset by joining
df = trip_data %>%
left_join(stop_times %>% select("trip_id", "stop_sequence", "arrival_time", "departure_time"),
by = c("trip_id" = "trip_id", "stop_sequence" = "stop_sequence")) %>%
left_join(stops %>% select("stop_id", "stop_lat", "stop_lon"),
by = c("stop_id" = "stop_id")) %>%
left_join(routes %>% select("route_id", "route_short_name"),
by = c("route_id" = "route_id")) %>%
left_join(cancelled_buses,
by = c("trip_id" = "trip_id"))
df = df[order(df$trip_id, df$direction_id, df$stop_sequence, df$arrival_time),]
df
#Since these times are in total seconds from Jan 1970, we need to convert them to hours for a given day
class(df$act_arrival_time) = c('POSIXt','POSIXct')
class(df$act_departure_time) = c('POSIXt','POSIXct')
df$act_arrival_time
df$act_arrival_time_in_seconds <- as.numeric(df$act_arrival_time)
df$act_arrival_time_in_seconds
df
c(10173376 - 9836781, 107314, - 336606, 3946703 - 3219541)
c(10173376 - 9836781, 107314 - 336606, 3946703 - 3219541)
c(10173376 - 9836781, 107314 - 336606, 3946703 - 3219541, 3946703 + 107314 + 10173376 - (3219541 + 336606 + 9836781))
c(10173376 - 9836781, 107314 - 336606, 3946703 - 3219541, total_change = 3946703 + 107314 + 10173376 - (3219541 + 336606 + 9836781))
c(Uber Change = 10173376 - 9836781, 107314 - 336606, 3946703 - 3219541, total_change = 3946703 + 107314 + 10173376 - (3219541 + 336606 + 9836781))
c(Uber = 10173376 - 9836781, Via = 107314 - 336606, Lyft = 3946703 - 3219541, Total = 3946703 + 107314 + 10173376 - (3219541 + 336606 + 9836781))
35359/3600
2 * 3600
1000/3600
1000/60
177/60
5623 / 3600
10^1 - 1
10 ^ 1.5
for(i in c(1,2)) {
print(i)
}
for(i in c(1,2)) {
print(i)
}
2.794e+01
1.440e+00
first = TRUE
i = 0
if (first) {
first = FALSE
i = i + 5
} else {
i = i + 1
}
first = TRUE
i = 0
if (first) {
first = FALSE
i = i + 5
} else {
i = i + 1
}
print(i)
10 ^ 0.8
library(xml2)
?xml_text
data.frame(x = 1, y = c(1,2), z = c(1,2,3,4))
system.time(print("hello world"))
x = function() {
t = seq(1, 100000)
lapply(t, FUN = function(y) {
y = y^3
})
}
system.time(x)
x
x
x = function() {
t = seq(1, 100000)
print(t)
lapply(t, FUN = function(y) {
y = y^3
})
}
x
system.time(x())
?system.time
library(parallel)
detectCores()
?lapply
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
x
lapply(x, mean)
mclapply(X, mean, mc.cores = 3)
mclapply(x, mean, mc.cores = 3)
x1 = function() {
lapply(x, mean)
}
x2 = function() {
mclapply(x, mean, mc.cores = 3)
}
system.time(x1)
system.time(x1())
x1()
x
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE), c = seq(1, 100), f = seq(1, 100000))
system.time(x1())
system.time(x2())
x2
16 * 0.219
35 + 79
79/114
35/39
6.922 + 1.053 * 40
(79)/ (79 + 35)
35/ 39
79 / (35 + 79)
35 / (35 + 79)
df1 <- data.frame(ID = 1:3, Value = c(10, 20, 30))
df2 <- data.frame(ID = 4:6, Value = c(40, 50, 60))
df3 <- data.frame(ID = 7:9, Value = c(70, 80, 90))
# Create a list of dataframes
list_of_dfs <- list(df1, df2, df3)
list_of_dfs
do.call(rbind, list_of_dfs)
?sapply
list_of_dfs
random = function(x) {
sum(x$Value)
}
sapply(list_of_dfs, random)
tapply(list_of_dfs, random)
lapply(list_of_dfs, random)
do.call(rbind, lapply(list_of_dfs, random))
class(do.call(rbind, lapply(list_of_dfs, random)))
as.integer(3.2)
as.double(3.2)
x = c(1,2,3)
x
names(x) = c("1", "2", "3")
x
p = 0.7755
e = seq(2,7)
e
p^e
0.8668 * 0.2847
source('businfoextraction.R')
setwd("~/Desktop/bus-visualisation-akl/NodeJS/TESTINGdatabase/extraction")
source('businfoextraction.R')
trips
stops
stop_times
