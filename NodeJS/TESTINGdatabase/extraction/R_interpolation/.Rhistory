valid_data = subset(arrival_bus, trip_id %in% other_ids)
arrival_bus = rbind(cleaned_problem,valid_data)
return(arrival_bus)
}
arrival_bus = problemLess(arrival_bus)
# Can have a problem where 35,37,35 need to first remove 37, then remove 35
problemEqual = function(arrival_bus) {
arrival_bus = arrival_bus %>%
group_by(trip_id) %>%
arrange(trip_id, act_arrival_time) %>%
mutate(diff_stop_sequence = stop_sequence - lag(stop_sequence))
# Get the problem data when there are sequences that are the same
pe = arrival_bus[sapply(arrival_bus$diff_stop_sequence, getEqualData), ]$trip_id
#problem_equal = subset(arrival_bus, trip_id %in% pe) %>%
#  select(trip_id, delay, act_arrival_time_date,stop_sequence, diff_stop_sequence)
problem_equal = subset(arrival_bus, trip_id %in% pe)
# The way to fix this issue is going to remove all the observations after the FIRST one
# Essentially just remove the 0's
cleaned_equal = problem_equal[is.na(problem_equal$diff_stop_sequence) | problem_equal$diff_stop_sequence != 0, ]
# Take the cleaned equal ids and the problem set ids and combine together!
# Then combine the dataset all together
ids = unique(arrival_bus$trip_id)
other_ids = ids[!ids %in% pe]
valid_data = subset(arrival_bus, trip_id %in% other_ids)
arrival_bus = rbind(cleaned_equal,valid_data)
return(arrival_bus)
}
arrival_bus = problemEqual(arrival_bus)
problemLead = function(arrival_bus) {
arrival_bus = arrival_bus %>%
group_by(trip_id) %>%
arrange(trip_id, act_arrival_time) %>%
mutate(lead_stop_sequence = lead(stop_sequence) - stop_sequence)
problem_data = arrival_bus[sapply(arrival_bus$lead_stop_sequence, getLessData), ]
problem_id = unique(problem_data$trip_id)
problem_set = subset(arrival_bus, trip_id %in% problem_id)
# Remove observations which stop_sequence is after another.
cleaned_problem = problem_set[is.na(problem_set$lead_stop_sequence) | problem_set$lead_stop_sequence >= 0, ]
# Then combine the dataset all together
ids = unique(arrival_bus$trip_id)
other_ids = ids[!ids %in% problem_id]
valid_data = subset(arrival_bus, trip_id %in% other_ids)
arrival_bus = rbind(cleaned_problem,valid_data)
return(arrival_bus)
}
arrival_bus = problemLead(arrival_bus)
arrival_bus = arrival_bus %>%
group_by(trip_id) %>%
arrange(trip_id, act_arrival_time) %>%
mutate(lead_stop_sequence = lead(stop_sequence) - stop_sequence,
diff_stop_sequence = stop_sequence - lag(stop_sequence))
# We see that this should be 0. As there should not be any ids that the less and equal have the same!
unique(arrival_bus[sapply(arrival_bus$diff_stop_sequence, getLessData), ]$trip_id)
unique(arrival_bus[sapply(arrival_bus$diff_stop_sequence, getEqualData), ]$trip_id)
unique(arrival_bus[sapply(arrival_bus$lead_stop_sequence, getLessData), ]$trip_id)
# Now we can combine all the data together! Want
# valid_data (data that was already right!)
# cleaned_data (data that has been cleaned)
# Columns I want for interpolation
# ("trip_id", "shape_id", "timestamps", "status", "stop_lat", "stop_lon", "route_id", "route_short_name")
# For non-cancelled trips we need to get the dataset
non_cancelled_trips = arrival_bus
# For places that don't have a shape_id nor lats or lon, we can get them.
non_cancelled_trips = left_join(non_cancelled_trips, stop_times, by = c("trip_id", "stop_id", "stop_sequence"))
non_cancelled_trips = left_join(non_cancelled_trips, trips %>% select(trip_id, shape_id), by = c("trip_id"))
# Seems like something is wrong here!! Need to ask Thomas Lumley
any(is.na(non_cancelled_trips$shape_id.y))
unique(non_cancelled_trips[is.na(non_cancelled_trips$shape_id.y),]$route_short_name)
# For non-cancelled trips we need to put in the first and last point
nc = non_cancelled_trips %>% select(trip_id, shape_id.x, timestamps, status, stop_lat, stop_lon, route_id, route_short_name, stop_sequence)
colnames(nc)[2] = "shape_id"
# We doing this for now until we fix it!
nc_hs = subset(nc, !is.na(shape_id))
splitted_nc_hs = split(nc_hs, nc_hs$trip_id)
# Function to get the first and last rows for teh dataset
getRemainingSequence = function(tripData) {
# This code already assumes you have the date and make sure we get the times that are valid!
fullSequence = subset(stop_times, trip_id == tripData$trip_id[1] & departure_time < "24:00:00")
# Checks to see if we got the start of the sequence
if (min(tripData$stop_sequence) != 1) {
# Get the dataset that has the first and earliest stop sequence
first_sequence = subset(fullSequence, stop_sequence %in% c(1, min(tripData$stop_sequence)))
# Get the difference in time stamps
first_sequence$timestamps = timestamp_conversion(first_sequence$departure_time)
#T Then we need to get the first stop lat and lon
first_stop_loc = which(first_sequence$stop_sequence == 1)
first_stop = first_sequence$stop_id[first_stop_loc]
first_stop = subset(stops, stop_id == first_stop)
# Difference between the new times
diff_time = abs(first_sequence$timestamps[2] - first_sequence$timestamps[1])
first_data_point = data.frame(trip_id = tripData$trip_id[1],
shape_id = tripData$shape_id[1],
timestamps = tripData$timestamps[1] - diff_time,
status = tripData$status[1],
stop_lat = first_stop$stop_lat,
stop_lon = first_stop$stop_lon,
route_id = tripData$route_id[1],
route_short_name = tripData$route_short_name[1],
stop_sequence = 1)
tripData = rbind(first_data_point, tripData)
}
# Might need to fix this code
# We want to specifically do less than. This is because of the edge case that a stop sequence is delayed but ends up at a very late time
if (max(tripData$stop_sequence) < max(fullSequence$stop_sequence)) {
# Create a dataframe which has the last stop sequence and the stop sequence we have in dataset
last_sequence = subset(fullSequence, stop_sequence %in% c(max(fullSequence$stop_sequence), max(tripData$stop_sequence)))
# Convert to right format
last_sequence$timestamps = timestamp_conversion(last_sequence$departure_time)
# THen get the stop lat and lon for that stop
last_stop_loc = which(last_sequence$stop_sequence == max(fullSequence$stop_sequence))
last_stop = last_sequence$stop_id[last_stop_loc]
last_stop = subset(stops, stop_id == last_stop)
# Get the difference
diff_time = abs(last_sequence$timestamps[2] - last_sequence$timestamps[1])
last_data_point = data.frame(trip_id = tripData$trip_id[1],
shape_id = tripData$shape_id[1],
# Add the additional time
timestamps = tripData$timestamps[nrow(tripData)] + diff_time,
status = tripData$status[nrow(tripData)],
stop_lat = last_stop$stop_lat,
stop_lon = last_stop$stop_lon,
route_id = tripData$route_id[1],
route_short_name = tripData$route_short_name[1],
stop_sequence = max(fullSequence$stop_sequence))
tripData = rbind(tripData, last_data_point)
}
# Just to make sure we return when the stop_sequence is arranged correctly!
return(tripData %>% arrange(stop_sequence))
}
# TESTING
testing = subset(arrival_bus, trip_id == "1033-32503-83100-2-bf12f98a")
testing
library(parallel)
# Want to use all the cores we have
cores = detectCores()
# Want to run using parallisation since it saves us alot of times! Would estimate around 9 minutes to complete if we were doing single core
valid_dataframes =  mclapply(splitted_nc_hs, getRemainingSequence, mc.cores=cores)
valid_dataframes = do.call(rbind, valid_dataframes)
missing_timestamp_conversion = function(dates, times) {
# Convert strings to dates and hms (hours, minutes, seconds) objects
useful_dates <- as.Date(dates)
time_objects <- hms(times)
# Extract hours from time_objects and calculate additional days
additional_days <- floor(hour(time_objects) / 24)
# Update the hours by taking modulo 24 and dates by adding additional_days
hours_updated <- hour(time_objects) %% 24
useful_dates <- useful_dates + additional_days
# Construct new HMS objects and combine with dates
new_times <- sprintf("%02d:%02d:%02d", hours_updated, minute(time_objects), second(time_objects))
timestamps <- ymd_hms(paste(useful_dates, new_times), tz = "UTC")
# Convert to numeric and return
as.numeric(timestamps)
}
valid_ids = unique(valid_dataframes$trip_id)
trip_route = trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = 'route_id') %>%
filter(!(route_short_name %in% trains) &
!(route_short_name %in% ships) &
!(trip_id %in% valid_ids))
missingPoints = subset(stop_times, trip_id %in% trip_route$trip_id)
# Function to get required rows within each group
getPointsExceed <- function(data) {
before_24 <- data %>%
filter(departure_time <= '24:00:00')
# If before_24 is empty, return an empty data frame
if(nrow(before_24) == 0) {
return(data.frame())
}
after_24_closest <- data %>%
filter(departure_time > '24:00:00') %>%
arrange(departure_time) %>%
head(1)
return(rbind(before_24, after_24_closest))
}
missingPoints = missingPoints %>%
group_by(trip_id) %>%
group_modify(~ getPointsExceed(.x))
# Converting the timestamps into seconds
# Paste the required date
missingPoints$timestamps = missing_timestamp_conversion(date_, missingPoints$departure_time)
missingPoints <- missingPoints %>%
left_join(stops %>% select(stop_id, stop_lat, stop_lon), by = "stop_id") %>%
left_join(trip_route, by = "trip_id") %>%
select(trip_id, shape_id, timestamps, stop_lat, stop_lon, route_id, route_short_name, stop_sequence)
missingPoints$status = 0
full_data = rbind(missingPoints, valid_dataframes)
full_data = full_data[is.na(full_data$timestamps) == FALSE,]
# Doing final checks, make sure we get the data for the required date
full_data = full_data %>% group_by(trip_id) %>% arrange(trip_id, stop_sequence)
write.csv(full_data, file = "complete_data.csv", row.names = FALSE)
setwd("~/Desktop/bus-visualisation-akl/NodeJS/TESTINGdatabase/extraction/R_interpolation")
# Get separate files
library(DBI)
library(RODBC)
library(odbc)
library(sf)
shape_paths = "../../shapefiles"
data_paths = "../../data"
complete_data <- read.csv("../complete_data.csv")
trip_id_groups <- split(complete_data, complete_data$trip_id)
for (trip_id in names(trip_id_groups)) {
filename <- paste0(data_paths,"/", trip_id, ".csv")
write.csv(trip_id_groups[[trip_id]], file = filename, row.names = FALSE)
}
con = dbConnect(RPostgres::Postgres(),
dbname = "bus_trial",
port = 5432,
user = "postgres",
password = "postgres",
host = "localhost")
routes = dbGetQuery(con, "SELECT * FROM shapes")
dbDisconnect(con)
route_groups <- split(routes, routes$shape_id)
for (shape_id in names(route_groups)) {
filename <- paste0(shape_paths,"/", shape_id, ".csv")
write.csv(route_groups[[shape_id]], file = filename, row.names = FALSE)
}
source("interpolate_function.R")
points_path = "../../data"
files = list.files(points_path)
# List to store the time taken for each file
time_taken_list <- list()
date_ = "2023-05-05"
runInterpolation = function() {
# Loop through each file
for(file_name in files) {
# Read the file
trip_data <- read.csv(paste0(points_path, "/", file_name))
# Measure the time taken to run interpolation() on this file
time_taken <- system.time({
interpolation(trip_data, date_)
})
# Save the elapsed time to the list
time_taken_list[[file_name]] <- time_taken["elapsed"]
# Print progress
cat(paste0("Processed ", file_name, " in ", time_taken["elapsed"], " seconds.\n"))
}
}
system.time(runInterpolation())
source("interpolate_function.R")
points_path = "../../data"
files = list.files(points_path)
# List to store the time taken for each file
time_taken_list <- list()
date_ = "2023-05-05"
runInterpolation = function() {
# Loop through each file
for(file_name in files) {
# Read the file
trip_data <- read.csv(paste0(points_path, "/", file_name))
interpolation(trip_data, date_)
}
}
system.time(runInterpolation())
source("interpolate_function.R")
points_path = "../../data"
files = list.files(points_path)
# List to store the time taken for each file
time_taken_list <- list()
date_ = "2023-05-05"
runInterpolation = function() {
# Loop through each file
for(file_name in files) {
# Read the file
trip_data <- read.csv(paste0(points_path, "/", file_name))
interpolation(trip_data, date_)
}
}
system.time(runInterpolation())
# Get separate files
library(DBI)
library(RODBC)
library(odbc)
library(sf)
shape_paths = "../../shapefiles"
data_paths = "../../data"
complete_data <- read.csv("../complete_data.csv")
trip_id_groups <- split(complete_data, complete_data$trip_id)
for (trip_id in names(trip_id_groups)) {
filename <- paste0(data_paths,"/", trip_id, ".csv")
write.csv(trip_id_groups[[trip_id]], file = filename, row.names = FALSE)
}
con = dbConnect(RPostgres::Postgres(),
dbname = "bus_trial",
port = 5432,
user = "postgres",
password = "postgres",
host = "localhost")
routes = dbGetQuery(con, "SELECT * FROM shapes")
dbDisconnect(con)
route_groups <- split(routes, routes$shape_id)
for (shape_id in names(route_groups)) {
filename <- paste0(shape_paths,"/", shape_id, ".csv")
write.csv(route_groups[[shape_id]], file = filename, row.names = FALSE)
}
source("interpolate_function.R")
points_path = "../../data"
files = list.files(points_path)
# List to store the time taken for each file
time_taken_list <- list()
date_ = "2023-05-05"
runInterpolation = function() {
# Loop through each file
for(file_name in files) {
# Read the file
trip_data <- read.csv(paste0(points_path, "/", file_name))
interpolation(trip_data, date_)
}
}
system.time(runInterpolation())
# Define function to process a single file
processFile <- function(file_name) {
# Read the file
trip_data <- read.csv(paste0(points_path, "/", file_name))
interpolation(trip_data, date_)
return(TRUE)  # This is a placeholder, you can return whatever you want or need
}
# Determine the number of cores to use
no_cores <- detectCores() - 1  # use one core less than the available ones to leave resources for other processes
# Use mclapply to run the function in parallel
results <- mclapply(files, processFile, mc.cores = no_cores)
# Measure time taken
system.time({
results <- mclapply(files, processFile, mc.cores = no_cores)
})
56440496
trip_route
trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = 'route_id')
routes
trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = 'route_id')
trips
trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id'))
routes %>% select(route_id, route_short_name)
rlang::last_trace()
routes
routes = read.table("../businfo/routes.txt", header = TRUE, sep = ",", quote = "")
setwd("~/Desktop/bus-visualisation-akl/NodeJS/TESTINGdatabase/extraction")
routes = read.table("../businfo/routes.txt", header = TRUE, sep = ",", quote = "")
routes = read.table("../businfo/routes.txt", header = TRUE, sep = ",", quote = "")
routes
trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id'))
files
results
?object.size
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intFiles
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intFiles
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intFiles
points_path = "../../data"
files = list.files(points_path)
files
setwd("~/Desktop/bus-visualisation-akl/NodeJS/TESTINGdatabase/extraction/R_interpolation")
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intFiles
intFiles
?gsub
gsub("$.csv", "", "x.csv")
gsub(".csv$", "", "x.csv")
intFiles
load_file[intFiles[1]]
load_file = function(x) {
points = read.csv(x)
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
}
load_file[intFiles[1]]
intFiles[1]
load_file[intFiles[1]]
load_file(intFiles[1])
setwd("~/Desktop/bus-visualisation-akl/NodeJS/TESTINGdatabase/extraction/R_interpolation")
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intPoints = data.frame()
load_file = function(x) {
points = read.csv(x)
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
}
load_file(intFiles[1])
load_file = function(x) {
points = read.csv(paste0("../../", x))
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
}
load_file(intFiles[1])
load_file = function(x) {
points = read.csv(paste0(interpolate_path, x))
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
}
load_file(intFiles[1])
load_file = function(x) {
points = read.csv(paste0(interpolate_path, "/",x))
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
}
load_file(intFiles[1])
load_file = function(x) {
points = read.csv(paste0(interpolate_path, "/",x))
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
return(points)
}
load_file(intFiles[1])
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intPoints = data.frame()
load_file = function(x) {
points = read.csv(paste0(interpolate_path, "/",x))
trip_id = gsub(".csv$", "", x)
points$trip_id = trip_id
return(points)
}
# Use lapply to read each file into a data frame and add to a list
intFilesApply = lapply(intFiles, load_file)
load_file("1018-44421-86400-2-c9122308.csv")
read.csv(paste0(interpolate_path, "/","1018-44421-86400-2-c9122308.csv"))
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intPoints = data.frame()
load_file = function(x) {
trip_id = gsub(".csv$", "", x)
points = read.csv(paste0(interpolate_path, "/",x))
if (length(points) == 0) {
print(trip_id)
return(data.frame())
}
points$trip_id = trip_id
return(points)
}
# Use lapply to read each file into a data frame and add to a list
intFilesApply = lapply(intFiles, load_file)
read.csv(paste0(interpolate_path, "/","1018-44421-86400-2-c9122308.csv"))
nrow(read.csv(paste0(interpolate_path, "/","1018-44421-86400-2-c9122308.csv")))
# Store all the data together
interpolate_path = "../../interpolation"
intFiles = list.files(interpolate_path)
intPoints = data.frame()
load_file = function(x) {
trip_id = gsub(".csv$", "", x)
points = read.csv(paste0(interpolate_path, "/",x))
if (nrow(points) == 0) {
print(trip_id)
return(data.frame())
}
points$trip_id = trip_id
return(points)
}
# Use lapply to read each file into a data frame and add to a list
intFilesApply = lapply(intFiles, load_file)
# Combine the list of data frames into a single data frame
intPoints = do.call(rbind, intFilesApply)
intPoints
trip_route = trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id')) %>%
filter(!(route_short_name %in% trains) &
!(route_short_name %in% ships) &
!(trip_id %in% valid_ids))
trip_route = trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id')) %>%
filter(!(route_short_name %in% trains) &
!(route_short_name %in% ships) &
!(trip_id %in% valid_ids))
trip_route
# Combine the list of data frames into a single data frame
intPoints = do.call(rbind, intFilesApply)
# Have to read from Processed_Data_WithoutCancel.R
trip_route = trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id')) %>%
filter(!(route_short_name %in% trains) &
!(route_short_name %in% ships) &
!(trip_id %in% valid_ids))
intPoints = intPoints %>% left_join(trip_route %>% select(trip_id, route_short_name), by = c("trip_id"))
intPoints
View(intPoints)
write.csv(intPoints, "interpolated_data.csv", row.names = FALSE)
intPoints
# Combine the list of data frames into a single data frame
intPoints = do.call(rbind, intFilesApply)
# Have to read from Processed_Data_WithoutCancel.R
trip_route = trips %>%
select(trip_id, route_id, shape_id) %>%
left_join(routes %>% select(route_id, route_short_name), by = c('route_id'))
intPoints = intPoints %>% left_join(trip_route %>% select(trip_id, route_short_name), by = c("trip_id"))
intPoints
subset(intPoints, trip_id == "1010-98109-18000-2-fc6666b6")
write.csv(intPoints, "interpolated_data.csv", row.names = FALSE)
