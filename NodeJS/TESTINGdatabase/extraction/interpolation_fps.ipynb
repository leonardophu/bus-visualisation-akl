{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geojson import LineString\n",
    "import pandas as pd\n",
    "import turfpy.measurement as turf_measurement\n",
    "from turfpy.measurement import along\n",
    "from typing import List, Tuple\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = 1\n",
    "\n",
    "# database account\n",
    "db_username = \"postgres\"\n",
    "db_password = \"postgres\"\n",
    "db_host = \"localhost\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"bus_trial\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_route_steps(timestamps) :\n",
    "    individual_steps = []\n",
    "    for i in range(len(timestamps) - 1):\n",
    "        difference = timestamps[i + 1] - timestamps[i]\n",
    "        multiplied_value = round(difference * multiplier)\n",
    "        individual_steps.append(multiplied_value)\n",
    "    return individual_steps\n",
    "\n",
    "def is_equal(coord1, coord2) :\n",
    "    return coord1[0] == coord2[0] and coord1[1] == coord2[1]\n",
    "\n",
    "def getShapeCoords(shape_id) :\n",
    "    print('shape')\n",
    "    # Create a database connection string\n",
    "    connection = psycopg2.connect(user=db_username,\n",
    "                                    password=db_password,\n",
    "                                    host=db_host,\n",
    "                                    port=db_port,\n",
    "                                    database=db_name)\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    #Get the shape data in the database\n",
    "    query = \"SELECT * FROM shapes WHERE shape_id = %s ORDER BY shape_pt_sequence\"\n",
    "    cursor.execute(query, (shape_id,))\n",
    "    # Get all the results\n",
    "    results = cursor.fetchall()\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    # Create a pandas dataframe\n",
    "    shape_df = pd.DataFrame(results, columns = ['id', 'shape_id', 'lat', 'lon', 'shape_pt_sequence'])\n",
    "    # Combine the coordinates together \n",
    "    shape_df['coordinates'] = shape_df.apply(lambda row: [row['lon'], row['lat']], axis=1)\n",
    "    # Get all the coordinates into one list \n",
    "    shape_coordinates = shape_df['coordinates'].tolist()\n",
    "    return(shape_coordinates)\n",
    "    \n",
    "def route_to_dict(route):\n",
    "    return {tuple(coord): idx for idx, coord in enumerate(route)}\n",
    "\n",
    "def interpolation_fps(subsetDataset) :\n",
    "    subsetDataset = subsetDataset.reset_index(drop=True)\n",
    "    unique_coordinates = subsetDataset[\"coordinates\"]\n",
    "    shape_id = str(subsetDataset[\"shape_id\"].unique()[0])\n",
    "    unique_timestamps = subsetDataset[\"timestamps\"]\n",
    "    unique_status = subsetDataset[\"status\"]\n",
    "    \n",
    "    # Get the bus route coordinates\n",
    "    unique_route = getShapeCoords(shape_id)\n",
    "    route_dict = route_to_dict(unique_route)\n",
    "\n",
    "    # Get the number of frames we want to allocate between each observatoin \n",
    "    unique_steps = unique_route_steps(unique_timestamps)\n",
    "    interpolated_points = []\n",
    "    status_conditions = [] \n",
    "\n",
    "\n",
    "    print(range(len(unique_timestamps) - 1))\n",
    "    for i in range(len(unique_timestamps) - 1):\n",
    "        # Check if the bus status has changed. If it has we need to change the colour of the bus \n",
    "        changed_bus = False\n",
    "        first_status = unique_status[i]\n",
    "    \n",
    "        if unique_status[i] != unique_status[i + 1]:\n",
    "            second_status = unique_status[i + 1]\n",
    "            changed_bus = True\n",
    "            status_difference = abs(second_status - first_status)\n",
    "\n",
    "        # subset coordinates are the coordinates we are interested in \n",
    "        subset_coordinates = []\n",
    "        start_point = unique_coordinates[i]\n",
    "        end_point = unique_coordinates[i + 1]\n",
    "\n",
    "        # J is a counter \n",
    "        j = 0\n",
    "\n",
    "        # Want to get all the points in between the current value and the next\n",
    "        while j < len(unique_route):\n",
    "            # Get the current value \n",
    "            current_coordinates = unique_route[j]\n",
    "\n",
    "            # If we find the value that we want (which is the current node)\n",
    "            if is_equal(current_coordinates, start_point):\n",
    "                # Put it into the coordinate system\n",
    "                subset_coordinates.append(current_coordinates)\n",
    "                # Collect all the points in between \n",
    "                while not is_equal(current_coordinates, end_point):\n",
    "                    j += 1\n",
    "                    current_coordinates = unique_route[j]\n",
    "                    subset_coordinates.append(current_coordinates)\n",
    "                break\n",
    "            j += 1\n",
    "\n",
    "        # Create a linestring object\n",
    "        line = LineString(subset_coordinates)\n",
    "\n",
    "        # Get the distance along the line \n",
    "        line_distance = turf_measurement.length(line)\n",
    "\n",
    "        if not changed_bus:\n",
    "            z = 0\n",
    "            while z < line_distance:\n",
    "                interpolated_point = along(line, z)\n",
    "                interpolated_points.append(tuple(interpolated_point['geometry']['coordinates']))\n",
    "                status_conditions.append(first_status)\n",
    "                z += line_distance / unique_steps[i]\n",
    "        else:\n",
    "            z = 0\n",
    "            while z < line_distance:\n",
    "                interpolated_point = along(line, z)\n",
    "                interpolated_points.append(tuple(interpolated_point['geometry']['coordinates']))\n",
    "\n",
    "                interpolation_index = z / line_distance\n",
    "\n",
    "                if status_difference == 1:\n",
    "                    if interpolation_index < 0.5:\n",
    "                        status = first_status\n",
    "                    else:\n",
    "                        status = second_status\n",
    "                elif status_difference == 2:\n",
    "                    if interpolation_index < 1/3:\n",
    "                        status = first_status\n",
    "                    elif 1/3 <= interpolation_index < 2/3:\n",
    "                        if first_status < second_status:\n",
    "                            status = first_status + 1\n",
    "                        else:\n",
    "                            status = first_status - 1\n",
    "                    else:\n",
    "                        status = second_status\n",
    "\n",
    "                status_conditions.append(status)\n",
    "                z += line_distance / unique_steps[i]\n",
    "\n",
    "    # With all the data that we have, we need to input them all into the sql database\n",
    "    startPoint = subsetDataset[\"timestamps\"].min().item()\n",
    "    route_name = subsetDataset['route_short_name'].unique()[0]\n",
    "    \n",
    "    # Create data for the DataFrame\n",
    "    data = []\n",
    "    for i, (point, status) in enumerate(zip(interpolated_points, status_conditions)):\n",
    "        row = {\n",
    "            'longitude': point[0],\n",
    "            'latitude': point[1],\n",
    "            'status_condition': status,\n",
    "            'route_name': route_name,\n",
    "            'timestamp': startPoint + i\n",
    "        }\n",
    "        data.append(row)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = pd.read_csv(\"complete_data.csv\")\n",
    "trial_data['coordinates'] = trial_data.apply(lambda row: [row['stop_lon'], row['stop_lat']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>status</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010-98109-18000-2-fc6666b6</td>\n",
       "      <td>1010-98109-d221c68a</td>\n",
       "      <td>1683262820</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.54528</td>\n",
       "      <td>174.70832</td>\n",
       "      <td>981-221</td>\n",
       "      <td>981</td>\n",
       "      <td>1</td>\n",
       "      <td>[174.70832, -36.54528]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010-98109-18000-2-fc6666b6</td>\n",
       "      <td>1010-98109-d221c68a</td>\n",
       "      <td>1683263392</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.57805</td>\n",
       "      <td>174.68896</td>\n",
       "      <td>981-221</td>\n",
       "      <td>981</td>\n",
       "      <td>7</td>\n",
       "      <td>[174.68896, -36.57805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010-98109-18000-2-fc6666b6</td>\n",
       "      <td>1010-98109-d221c68a</td>\n",
       "      <td>1683264039</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.60968</td>\n",
       "      <td>174.68729</td>\n",
       "      <td>981-221</td>\n",
       "      <td>981</td>\n",
       "      <td>20</td>\n",
       "      <td>[174.68729, -36.60968]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010-98109-18000-2-fc6666b6</td>\n",
       "      <td>1010-98109-d221c68a</td>\n",
       "      <td>1683264244</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.62406</td>\n",
       "      <td>174.66652</td>\n",
       "      <td>981-221</td>\n",
       "      <td>981</td>\n",
       "      <td>21</td>\n",
       "      <td>[174.66652, -36.62406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010-98109-19800-2-fc6666b6</td>\n",
       "      <td>1010-98109-d221c68a</td>\n",
       "      <td>1683264623</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.54528</td>\n",
       "      <td>174.70832</td>\n",
       "      <td>981-221</td>\n",
       "      <td>981</td>\n",
       "      <td>1</td>\n",
       "      <td>[174.70832, -36.54528]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81865</th>\n",
       "      <td>957-12602-68400-2-ea1af35a</td>\n",
       "      <td>957-12602-45320708</td>\n",
       "      <td>1683315763</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.72212</td>\n",
       "      <td>174.71207</td>\n",
       "      <td>126-206</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>[174.71207, -36.72212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81866</th>\n",
       "      <td>957-12603-19200-2-953b0419</td>\n",
       "      <td>957-12603-1bf4bceb</td>\n",
       "      <td>1683264001</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.75751</td>\n",
       "      <td>174.59198</td>\n",
       "      <td>126-206</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>[174.59198, -36.75751]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81867</th>\n",
       "      <td>957-12603-19200-2-953b0419</td>\n",
       "      <td>957-12603-1bf4bceb</td>\n",
       "      <td>1683264109</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.76618</td>\n",
       "      <td>174.58738</td>\n",
       "      <td>126-206</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>[174.58738, -36.76618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81868</th>\n",
       "      <td>957-12603-19200-2-953b0419</td>\n",
       "      <td>957-12603-1bf4bceb</td>\n",
       "      <td>1683264581</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.81375</td>\n",
       "      <td>174.60895</td>\n",
       "      <td>126-206</td>\n",
       "      <td>126</td>\n",
       "      <td>11</td>\n",
       "      <td>[174.60895, -36.81375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81869</th>\n",
       "      <td>957-12603-19200-2-953b0419</td>\n",
       "      <td>957-12603-1bf4bceb</td>\n",
       "      <td>1683264691</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.82239</td>\n",
       "      <td>174.61100</td>\n",
       "      <td>126-206</td>\n",
       "      <td>126</td>\n",
       "      <td>12</td>\n",
       "      <td>[174.611, -36.82239]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81870 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trip_id             shape_id  timestamps  status  \\\n",
       "0      1010-98109-18000-2-fc6666b6  1010-98109-d221c68a  1683262820       1   \n",
       "1      1010-98109-18000-2-fc6666b6  1010-98109-d221c68a  1683263392       1   \n",
       "2      1010-98109-18000-2-fc6666b6  1010-98109-d221c68a  1683264039       1   \n",
       "3      1010-98109-18000-2-fc6666b6  1010-98109-d221c68a  1683264244       1   \n",
       "4      1010-98109-19800-2-fc6666b6  1010-98109-d221c68a  1683264623       1   \n",
       "...                            ...                  ...         ...     ...   \n",
       "81865   957-12602-68400-2-ea1af35a   957-12602-45320708  1683315763       1   \n",
       "81866   957-12603-19200-2-953b0419   957-12603-1bf4bceb  1683264001       1   \n",
       "81867   957-12603-19200-2-953b0419   957-12603-1bf4bceb  1683264109       1   \n",
       "81868   957-12603-19200-2-953b0419   957-12603-1bf4bceb  1683264581       1   \n",
       "81869   957-12603-19200-2-953b0419   957-12603-1bf4bceb  1683264691       1   \n",
       "\n",
       "       stop_lat   stop_lon route_id route_short_name  stop_sequence  \\\n",
       "0     -36.54528  174.70832  981-221              981              1   \n",
       "1     -36.57805  174.68896  981-221              981              7   \n",
       "2     -36.60968  174.68729  981-221              981             20   \n",
       "3     -36.62406  174.66652  981-221              981             21   \n",
       "4     -36.54528  174.70832  981-221              981              1   \n",
       "...         ...        ...      ...              ...            ...   \n",
       "81865 -36.72212  174.71207  126-206              126             27   \n",
       "81866 -36.75751  174.59198  126-206              126              1   \n",
       "81867 -36.76618  174.58738  126-206              126              4   \n",
       "81868 -36.81375  174.60895  126-206              126             11   \n",
       "81869 -36.82239  174.61100  126-206              126             12   \n",
       "\n",
       "                  coordinates  \n",
       "0      [174.70832, -36.54528]  \n",
       "1      [174.68896, -36.57805]  \n",
       "2      [174.68729, -36.60968]  \n",
       "3      [174.66652, -36.62406]  \n",
       "4      [174.70832, -36.54528]  \n",
       "...                       ...  \n",
       "81865  [174.71207, -36.72212]  \n",
       "81866  [174.59198, -36.75751]  \n",
       "81867  [174.58738, -36.76618]  \n",
       "81868  [174.60895, -36.81375]  \n",
       "81869    [174.611, -36.82239]  \n",
       "\n",
       "[81870 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Create a multiprocessing Pool and map the worker function to the groups\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m Pool(num_cores) \u001b[39mas\u001b[39;00m pool:\n\u001b[0;32m---> 14\u001b[0m     result_dataframes \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(worker, groups)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Concatenate all resulting DataFrames\u001b[39;00m\n\u001b[1;32m     17\u001b[0m combined_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(result_dataframes, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "# Split groups into a list so they can be processed in parallel\n",
    "groups = [group for _, group in trial_data.groupby('trip_id')]\n",
    "\n",
    "# Create a worker function to process each group\n",
    "def worker(group):\n",
    "    return interpolation_fps(group)\n",
    "\n",
    "# Use all available CPU cores\n",
    "num_cores = cpu_count()\n",
    "\n",
    "# Create a multiprocessing Pool and map the worker function to the groups\n",
    "with Pool(num_cores) as pool:\n",
    "    result_dataframes = pool.map(worker, groups)\n",
    "\n",
    "# Concatenate all resulting DataFrames\n",
    "combined_dataframe = pd.concat(result_dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trial_data\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mtrip_id\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(interpolation_fps)\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1567\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     new_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1560\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe operation \u001b[39m\u001b[39m{\u001b[39;00morig_func\u001b[39m}\u001b[39;00m\u001b[39m failed on a column. If any error is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraised, this will raise an exception in a future version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof pandas. Drop these columns to avoid this warning.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m     )\n\u001b[1;32m   1564\u001b[0m     \u001b[39mwith\u001b[39;00m rewrite_warning(\n\u001b[1;32m   1565\u001b[0m         old_msg, \u001b[39mFutureWarning\u001b[39;00m, new_msg\n\u001b[1;32m   1566\u001b[0m     ) \u001b[39mif\u001b[39;00m is_np_func \u001b[39melse\u001b[39;00m nullcontext():\n\u001b[0;32m-> 1567\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[1;32m   1568\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m     \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m     \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_selection_context():\n\u001b[1;32m   1578\u001b[0m         \u001b[39m# GH#50538\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1629\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1594\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1600\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1601\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[1;32m   1630\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36minterpolation_fps\u001b[0;34m(subsetDataset)\u001b[0m\n\u001b[1;32m     48\u001b[0m unique_route \u001b[39m=\u001b[39m getShapeCoords(shape_id)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Get the number of frames we want to allocate between each observatoin \u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m unique_steps \u001b[39m=\u001b[39m unique_route_steps(unique_timestamps)\n\u001b[1;32m     53\u001b[0m interpolated_points \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m status_conditions \u001b[39m=\u001b[39m [] \n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36munique_route_steps\u001b[0;34m(timestamps)\u001b[0m\n\u001b[1;32m      2\u001b[0m individual_steps \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(timestamps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     difference \u001b[39m=\u001b[39m timestamps[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39m timestamps[i]\n\u001b[1;32m      5\u001b[0m     multiplied_value \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(difference \u001b[39m*\u001b[39m multiplier)\n\u001b[1;32m      6\u001b[0m     individual_steps\u001b[39m.\u001b[39mappend(multiplied_value)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "trial_data.groupby('trip_id').apply(interpolation_fps).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Subject  Score  Normalized\n",
      "0    Alice     Math     85   -1.044074\n",
      "1      Bob     Math     89    0.094916\n",
      "2  Charlie     Math     92    0.949158\n",
      "3    Alice  Physics     70   -1.072222\n",
      "4      Bob  Physics     75    0.164957\n",
      "5  Charlie  Physics     78    0.907265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-48e8dbb1c54e>:18: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_normalized = df.groupby('Subject').apply(normalize_scores)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Charlie'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Physics', 'Physics', 'Physics'],\n",
    "    'Score': [85, 89, 92, 70, 75, 78]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to normalize scores\n",
    "def normalize_scores(group):\n",
    "    group['Normalized'] = (group['Score'] - group['Score'].mean()) / group['Score'].std()\n",
    "    return group\n",
    "\n",
    "# Group by 'Subject' and apply the normalization\n",
    "df_normalized = df.groupby('Subject').apply(normalize_scores)\n",
    "\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Subject  Score\n",
      "0    Alice     Math     85\n",
      "1      Bob     Math     89\n",
      "2  Charlie     Math     92\n",
      "3    Alice  Physics     70\n",
      "4      Bob  Physics     75\n",
      "5  Charlie  Physics     78\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
