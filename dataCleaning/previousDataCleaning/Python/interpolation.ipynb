{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geojson import LineString\n",
    "import pandas as pd\n",
    "import turfpy.measurement as turf_measurement\n",
    "from turfpy.measurement import along\n",
    "from typing import List, Tuple\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = 1\n",
    "\n",
    "# database account\n",
    "db_username = \"postgres\"\n",
    "db_password = \"postgres\"\n",
    "db_host = \"localhost\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"bus_trial\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeData(coordinates, status, route, startPoint) :\n",
    "\n",
    "    # Create a database connection string\n",
    "    connection = psycopg2.connect(user=db_username,\n",
    "                                    password=db_password,\n",
    "                                    host=db_host,\n",
    "                                    port=db_port,\n",
    "                                    database=db_name)\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    nested_coordinate_list = [[float(item) for item in sublist] for sublist in coordinates]\n",
    "    status_list = [int(item) for item in status]\n",
    "\n",
    "    cursor.execute(\n",
    "    \"INSERT INTO points (int_points, bus_status, bus_number, start_time) VALUES (%s, %s, %s, %s)\",\n",
    "    (nested_coordinate_list, status_list, route, startPoint)\n",
    "    )\n",
    "    connection.commit()\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "def unique_route_steps(timestamps) :\n",
    "    individual_steps = []\n",
    "    for i in range(len(timestamps) - 1):\n",
    "        difference = timestamps[i + 1] - timestamps[i]\n",
    "        multiplied_value = round(difference * multiplier)\n",
    "        individual_steps.append(multiplied_value)\n",
    "    return individual_steps\n",
    "\n",
    "def is_equal(coord1, coord2) :\n",
    "    return coord1[0] == coord2[0] and coord1[1] == coord2[1]\n",
    "\n",
    "def getShapeCoords(shape_id) :\n",
    "    # Create a database connection string\n",
    "    connection = psycopg2.connect(user=db_username,\n",
    "                                    password=db_password,\n",
    "                                    host=db_host,\n",
    "                                    port=db_port,\n",
    "                                    database=db_name)\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    #Get the shape data in the database\n",
    "    query = \"SELECT * FROM shapes WHERE shape_id = %s ORDER BY shape_pt_sequence\"\n",
    "    cursor.execute(query, (shape_id,))\n",
    "    # Get all the results\n",
    "    results = cursor.fetchall()\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    # Create a pandas dataframe\n",
    "    shape_df = pd.DataFrame(results, columns = ['id', 'shape_id', 'lat', 'lon', 'shape_pt_sequence'])\n",
    "    # Combine the coordinates together \n",
    "    shape_df['coordinates'] = shape_df.apply(lambda row: [row['lon'], row['lat']], axis=1)\n",
    "    # Get all the coordinates into one list \n",
    "    shape_coordinates = shape_df['coordinates'].tolist()\n",
    "    return(shape_coordinates)\n",
    "    \n",
    "\n",
    "def interpolation(subsetDataset) :\n",
    "    subsetDataset = subsetDataset.reset_index(drop=True)\n",
    "    unique_coordinates = subsetDataset[\"coordinates\"]\n",
    "    shape_id = str(subsetDataset[\"shape_id\"].unique()[0])\n",
    "    unique_timestamps = subsetDataset[\"timestamps\"]\n",
    "    unique_status = subsetDataset[\"status\"]\n",
    "    \n",
    "    # Get the bus route coordinates\n",
    "    unique_route = getShapeCoords(shape_id)\n",
    "\n",
    "    # Get the number of frames we want to allocate between each observatoin \n",
    "    unique_steps = unique_route_steps(unique_timestamps)\n",
    "    \n",
    "    interpolated_points = []\n",
    "    status_conditions = [] \n",
    "    # First is used to see if we are looking at the first observation \n",
    "    first = True\n",
    "\n",
    "    for i in range(len(unique_timestamps) - 1):\n",
    "        # Check if the bus status has changed. If it has we need to change the colour of the bus \n",
    "        changed_bus = False\n",
    "        first_status = unique_status[i]\n",
    "    \n",
    "        if unique_status[i] != unique_status[i + 1]:\n",
    "            second_status = unique_status[i + 1]\n",
    "            changed_bus = True\n",
    "            status_difference = abs(second_status - first_status)\n",
    "\n",
    "        # subset coordinates are the coordinates we are interested in \n",
    "        subset_coordinates = []\n",
    "        start_point = unique_coordinates[i]\n",
    "        end_point = unique_coordinates[i + 1]\n",
    "\n",
    "        # J is a counter \n",
    "        j = 0\n",
    "\n",
    "        # Want to get all the points in between the current value and the next\n",
    "        while j < len(unique_route):\n",
    "            # Get the current value \n",
    "            current_coordinates = unique_route[j]\n",
    "\n",
    "            # If we find the value that we want (which is the current node)\n",
    "            if is_equal(current_coordinates, start_point):\n",
    "                # Put it into the coordinate system\n",
    "                subset_coordinates.append(current_coordinates)\n",
    "                # Collect all the points in between \n",
    "                while not is_equal(current_coordinates, end_point):\n",
    "                    j += 1\n",
    "                    current_coordinates = unique_route[j]\n",
    "                    subset_coordinates.append(current_coordinates)\n",
    "                break\n",
    "            j += 1\n",
    "\n",
    "        # Create a linestring object\n",
    "        line = LineString(subset_coordinates)\n",
    "\n",
    "        # Get the distance along the line \n",
    "        line_distance = turf_measurement.length(line)\n",
    "\n",
    "        if not changed_bus:\n",
    "            z = 0\n",
    "            while z < line_distance:\n",
    "                interpolated_point = along(line, z)\n",
    "                interpolated_points.append(tuple(interpolated_point['geometry']['coordinates']))\n",
    "                status_conditions.append(first_status)\n",
    "                z += line_distance / unique_steps[i]\n",
    "        else:\n",
    "            z = 0\n",
    "            while z < line_distance:\n",
    "                interpolated_point = along(line, z)\n",
    "                interpolated_points.append(tuple(interpolated_point['geometry']['coordinates']))\n",
    "\n",
    "                interpolation_index = z / line_distance\n",
    "\n",
    "                if status_difference == 1:\n",
    "                    if interpolation_index < 0.5:\n",
    "                        status = first_status\n",
    "                    else:\n",
    "                        status = second_status\n",
    "                elif status_difference == 2:\n",
    "                    if interpolation_index < 1/3:\n",
    "                        status = first_status\n",
    "                    elif 1/3 <= interpolation_index < 2/3:\n",
    "                        if first_status < second_status:\n",
    "                            status = first_status + 1\n",
    "                        else:\n",
    "                            status = first_status - 1\n",
    "                    else:\n",
    "                        status = second_status\n",
    "\n",
    "                status_conditions.append(status)\n",
    "                z += line_distance / unique_steps[i]\n",
    "    \n",
    "    # With all the data that we have, we need to input them all into the sql database\n",
    "    startPoint = subsetDataset[\"timestamps\"].min().item()\n",
    "    route_name = subsetDataset['route_short_name'].unique()[0]\n",
    "\n",
    "    # Function store data gets the dataset and stores it\n",
    "    storeData(interpolated_points, status_conditions, route_name, startPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = pd.read_csv(\"complete_data.csv\")\n",
    "trial_data['coordinates'] = trial_data.apply(lambda row: [row['stop_lon'], row['stop_lat']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'trip_id'\n",
    "grouped = trial_data.groupby('trip_id')\n",
    "\n",
    "# Get the trip_ids\n",
    "subset_groups = [grouped.get_group(x) for x in list(grouped.groups.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting Parallelisation. Though most didn't work :(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m----> 5\u001b[0m     executor\u001b[39m.\u001b[39mmap(interpolation, subset_groups)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1061\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1081\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(interpolation, subset_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'trip_id' and get the first N groups\n",
    "n_groups = 10  # number of groups you want\n",
    "grouped = trial_data.groupby('trip_id')\n",
    "subset = grouped.head(1).iloc[:n_groups]\n",
    "# Get the indices of the groups and create a subset of the dataframe\n",
    "indices = subset.index\n",
    "subset_df = trial_data.loc[trial_data.index.isin(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError processing group: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m n_cores \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mcpu_count()\n\u001b[0;32m---> 18\u001b[0m parallelize_dataframe(subset_df, interpolation_wrapper, n_cores)\n",
      "Cell \u001b[0;32mIn[167], line 6\u001b[0m, in \u001b[0;36mparallelize_dataframe\u001b[0;34m(df, func, n_cores)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallelize_dataframe\u001b[39m(df, func, n_cores\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m):\n\u001b[1;32m      5\u001b[0m     pool \u001b[39m=\u001b[39m Pool(n_cores)\n\u001b[0;32m----> 6\u001b[0m     pool\u001b[39m.\u001b[39;49mmap(func, [group \u001b[39mfor\u001b[39;49;00m name, group \u001b[39min\u001b[39;49;00m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mtrip_id\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n\u001b[1;32m      7\u001b[0m     pool\u001b[39m.\u001b[39mclose()\n\u001b[1;32m      8\u001b[0m     pool\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    pool = Pool(n_cores)\n",
    "    pool.map(func, [group for name, group in df.groupby('trip_id')])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "def interpolation_wrapper(group):\n",
    "    try:\n",
    "        group = group.reset_index(drop=True)\n",
    "        return interpolation(group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group: {e}\")\n",
    "\n",
    "n_cores = os.cpu_count()\n",
    "parallelize_dataframe(subset_df, interpolation_wrapper, n_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(cpu_count()) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m      5\u001b[0m         p\u001b[39m.\u001b[39mmap(func, [group \u001b[39mfor\u001b[39;00m name, group \u001b[39min\u001b[39;00m dfGrouped])\n\u001b[0;32m----> 7\u001b[0m applyParallel(trial_data\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mtrip_id\u001b[39;49m\u001b[39m'\u001b[39;49m), interpolation)\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mapplyParallel\u001b[0;34m(dfGrouped, func)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapplyParallel\u001b[39m(dfGrouped, func):\n\u001b[1;32m      4\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(cpu_count()) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m----> 5\u001b[0m         p\u001b[39m.\u001b[39;49mmap(func, [group \u001b[39mfor\u001b[39;49;00m name, group \u001b[39min\u001b[39;49;00m dfGrouped])\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    with Pool(cpu_count()) as p:\n",
    "        p.map(func, [group for name, group in dfGrouped])\n",
    "\n",
    "applyParallel(trial_data.groupby('trip_id'), interpolation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(cpu_count()) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m      3\u001b[0m         p\u001b[39m.\u001b[39mmap(func, [group\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m name, group \u001b[39min\u001b[39;00m dfGrouped])\n\u001b[0;32m----> 4\u001b[0m applyParallel(trial_data\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mtrip_id\u001b[39;49m\u001b[39m'\u001b[39;49m), interpolation)\n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mapplyParallel\u001b[0;34m(dfGrouped, func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapplyParallel\u001b[39m(dfGrouped, func):\n\u001b[1;32m      2\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(cpu_count()) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m----> 3\u001b[0m         p\u001b[39m.\u001b[39;49mmap(func, [group\u001b[39m.\u001b[39;49mreset_index(drop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mfor\u001b[39;49;00m name, group \u001b[39min\u001b[39;49;00m dfGrouped])\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/lab/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    with Pool(cpu_count()) as p:\n",
    "        p.map(func, [group.reset_index(drop=True) for name, group in dfGrouped])\n",
    "applyParallel(trial_data.groupby('trip_id'), interpolation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
